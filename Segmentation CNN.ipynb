{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation CNN\n",
    "\n",
    "@ysbecca\n",
    "Basic CNN to perform segmentation of training set based on layers:\n",
    "- epithelial layer\n",
    "- submucosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.python.client import device_lib\n",
    "from importlib import reload\n",
    "import math    \n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import scripts.helper_functions as hf\n",
    "import scripts.cnn_helper as cn\n",
    "import scripts.dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts.dataset' from '/Users/ysbecca/ysbecca-projects/bcsp-expert/scripts/dataset.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoints_dir = \"/Users/ysbecca/ysbecca-projects/bcsp-expert/checkpoints/\"\n",
    "\n",
    "# Image params\n",
    "img_size = 32\n",
    "num_channels = 3\n",
    "img_size_flat = img_size * img_size * num_channels\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Convolutional layer params\n",
    "filter_sizes = [3, 3]\n",
    "num_filters = [16, 32]\n",
    "num_layers = len(filter_sizes)\n",
    "\n",
    "max_pools = [2, 2]\n",
    "\n",
    "# Fully connected layers, followed by classification layer.\n",
    "fc_1_size = 128\n",
    "\n",
    "num_classes = 2\n",
    "weight_values = [1.0, 4.5] # 4= 20/80 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build TensorFlow graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "\n",
    "y_true = tf.placeholder(tf.int8, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) # So that we can control dropout.\n",
    "\n",
    "weights = tf.placeholder(tf.float32, shape=[None], name='weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find device configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU devices found: []\n"
     ]
    }
   ],
   "source": [
    "gpus = [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "num_gpus = len(gpus)\n",
    "print(\"GPU devices found: \" + str(gpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(x_image_, y_true_, weights_):\n",
    "    ''' Expecting the following parameters, in batches:\n",
    "        x_image_ - x_image\n",
    "        y_true_ - y_true\n",
    "    '''\n",
    "    network, _ = cn.new_conv_layer(input=x_image_,\n",
    "                                  num_input_channels=num_channels,\n",
    "                                  filter_size=filter_sizes[0],\n",
    "                                  num_filters=num_filters[0],\n",
    "                                  use_pooling=True,\n",
    "                                  max_pool_size=max_pools[0])\n",
    "    \n",
    "    network = tf.nn.dropout(network, keep_prob=keep_prob)\n",
    "    network, _ = cn.new_conv_layer(input=network,\n",
    "                                  num_input_channels=num_filters[0],\n",
    "                                  filter_size=filter_sizes[1],\n",
    "                                  num_filters=num_filters[1],\n",
    "                                  use_pooling=True,\n",
    "                                  max_pool_size=max_pools[1])\n",
    "    network = tf.nn.dropout(network, keep_prob=keep_prob)\n",
    "    network, num_fc_features = cn.flatten_layer(network) # 256\n",
    "    \n",
    "    # Flatten and build the fully-connected layers.\n",
    "    network, _ = cn.new_fc_layer(input=network,\n",
    "                             num_inputs=num_fc_features,\n",
    "                             num_outputs=fc_1_size,\n",
    "                             use_relu=False)\n",
    "    network, _ = cn.new_fc_layer(input=network,          \n",
    "                             num_inputs=fc_1_size,\n",
    "                             num_outputs=num_classes,\n",
    "                             use_relu=True)\n",
    "\n",
    "    y_pred = tf.nn.softmax(network)                    \n",
    "    y_pred_cls = tf.argmax(network, dimension=1)\n",
    "    \n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=network, labels=y_true_)\n",
    "    #cost = tf.reduce_mean(cross_entropy)\n",
    "    cost = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=network, onehot_labels=y_true_, weights=weights_))\n",
    "    \n",
    "    return y_pred, y_pred_cls, cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split operations (optionally) across GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_parallel(fn, num_gpus, **kwargs):\n",
    "    in_splits = {}\n",
    "    for k, v in kwargs.items():\n",
    "        in_splits[k] = tf.split(v, num_gpus)\n",
    "\n",
    "    y_pred_split, y_pred_cls_split, cost_split = [], [], []\n",
    "    for i in range(num_gpus):\n",
    "        with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)):\n",
    "            with tf.variable_scope(tf.get_variable_scope(), reuse=i > 0):\n",
    "                y_pred_, y_pred_cls_, cost_ = fn(**{k : v[i] for k, v in in_splits.items()})\n",
    "                y_pred_split.append(y_pred_)\n",
    "                y_pred_cls_split.append(y_pred_cls_)\n",
    "                cost_split.append(cost_)\n",
    "\n",
    "    return tf.concat(y_pred_split, axis=0), tf.concat(y_pred_cls_split, axis=0), tf.stack(cost_split, axis=0)\n",
    "\n",
    "if num_gpus > 0:\n",
    "    total_batches = num_gpus\n",
    "else:\n",
    "    total_batches = 1\n",
    "\n",
    "# train_batch_size = train_batch_size * total_batches\n",
    "# test_batch_size = test_batch_size * total_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cost and loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 16, 16, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_1:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 8, 8, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "if num_gpus > 0:\n",
    "    # Remember that this adds significant latency for CPU<->GPU copying of shared variables.\n",
    "    # 2 GPU's is enough to get a good balance between speedup and minimal latency (12 GB on k80 nodes)\n",
    "    y_pred, y_pred_cls, cost = make_parallel(model, num_gpus, x_image_=x_image, y_true_=y_true, weights_=weights)\n",
    "else:\n",
    "    # CPU-only version\n",
    "    y_pred, y_pred_cls, cost = model(x_image_=x_image, y_true_=y_true, weights_=weights)\n",
    "    \n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if num_gpus > 0: # Log GPU/CPU placement to the terminal if using GPU's.\n",
    "    session = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "else:\n",
    "    session = tf.Session()\n",
    "    \n",
    "session.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver() # For when we want to save the model.\n",
    "\n",
    "# Global ounter for total number of iterations performed so far.\n",
    "total_iterations = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supporting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(iterations=False):\n",
    "    model_name = 'm-' + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\") + \"-\"\n",
    "    if iterations:\n",
    "        model_name += str(iterations)\n",
    "    else:\n",
    "        model_name += str(total_iterations)\n",
    "    \n",
    "    save_path = saver.save(session, checkpoints_dir + model_name)\n",
    "    print(\"Model saved: \" + model_name)\n",
    "\n",
    "def restore_model(model_name):\n",
    "    saver.restore(sess=session, save_path=checkpoints_dir + model_name) \n",
    "    \n",
    "def generate_batch_weights(labels):\n",
    "    weights_ = []\n",
    "    for i, l in enumerate(labels):\n",
    "        for i in range(num_classes):\n",
    "            if l[i] == 1:\n",
    "                weights_.append(weight_values[i])\n",
    "    return weights_\n",
    "    \n",
    "def optimize(dataset_train, num_iterations, dropout_keep_prob=0.9, print_opt_acc=True, epoch=0, it_per_epoch=1):\n",
    "    global total_iterations\n",
    "    \n",
    "    #start_time = time.time()\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "        x_batch, y_true_batch = dataset_train.next_batch(train_batch_size)\n",
    "        x_batch = x_batch.reshape(len(x_batch), img_size_flat)\n",
    "        \n",
    "        weights_ = generate_batch_weights(y_true_batch)\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch, keep_prob: dropout_keep_prob, weights: weights_}\n",
    "\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every few iterations (a big few).\n",
    "        if i % it_per_epoch == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            if print_opt_acc:\n",
    "                msg = \"Epoch: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "                print(msg.format(epoch + 1, acc))\n",
    "                \n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    #end_time = time.time()\n",
    "    #time_dif = end_time - start_time\n",
    "    #if not silent:\n",
    "    #    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "def print_test_accuracy(dataset_test, show_confusion_matrix=True, quieter=False, silent=False):\n",
    "    num_test = len(dataset_test.images)\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        curr_batch_size = j - i\n",
    "        \n",
    "        # Get the images and targets from the test-set between index i and j.\n",
    "        images = dataset_test.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "        labels = dataset_test.labels[i:j, :]\n",
    "        feed_dict = {x: images, y_true: labels, keep_prob: 1.0}\n",
    "\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        i = j\n",
    "\n",
    "    test_cls_pred = [np.argmax(l) for l in cls_pred]\n",
    "    cls_true = [np.argmax(l) for l in dataset_test.labels]\n",
    "    \n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = np.equal(cls_true, test_cls_pred)\n",
    "    correct_sum = np.sum(correct)\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    msg = \"======== Accuracy on validation set: {0:.1%} ({1} / {2})\"\n",
    "    if not quieter:\n",
    "        print(msg.format(acc, correct_sum, num_test))\n",
    "    else:\n",
    "        if not silent:\n",
    "            print(\"{0:.1%}\".format(acc))\n",
    "    if show_confusion_matrix:\n",
    "        cn.plot_confusion_matrix(cls_true, cls_pred=test_cls_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases: ['0001', '0002']\n",
      "Selected: [ 0.  1.]\n",
      "LOADED k-set: 1\n",
      "Selected: [ 1.  0.]\n",
      "LOADED k-set: 0\n",
      "H&E stain augment...196859\n",
      "Rotational augment...1771731\n"
     ]
    }
   ],
   "source": [
    "reload(ds)\n",
    "k = 2\n",
    "dataset = ds.read_datasets(valid_id=1, train_id=0, k=k, shuffle_all=True, do_augments=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 1200\n",
    "# hf.show_labeled_patches(dataset.train.images[start:], dataset.train.labels[start:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = train_batch_size # or, validation batch size\n",
    "\n",
    "# TODO for now, since only 1 training set, no switching of training sets during training.\n",
    "def train_model(num_epochs, k, epochs_per_iteration=1):\n",
    "\n",
    "    # Calculate how many iterations per epoch based on batch size\n",
    "    it_per_epoch = math.ceil(dataset.train.num_images / train_batch_size)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        optimize(dataset.train, it_per_epoch, epoch=epoch, it_per_epoch=it_per_epoch)\n",
    "        print_test_accuracy(dataset.valid, show_confusion_matrix=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_model(10, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_model(25, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training set conf matrix:\")\n",
    "print_test_accuracy(dataset.train, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print_test_accuracy(dataset.train, show_confusion_matrix=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
